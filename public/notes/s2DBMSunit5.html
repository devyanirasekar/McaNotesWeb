<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="notes.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css">
    <title>SEM2 DBMS Unit-5</title>
</head>
<body>
    
    <nav class="nav-container">
        <div class="text_logo">
            <h2 class="logo">MCA_<span class="notes_text"> Notes</span></h2>
        </div>

        <ul class="list">
            <a href="/index.html"><li class="listno list-diplay">Home</li></a>
            <li class="listno list-diplay">About</li>
            <li class="listno list-diplay">Contact</li>
            <li><span class="download list-diplay" id="download">Download</span></li>
            <li class="toggle"><i class="fa-solid fa-bars fa-lg toggle-btn"></i></li>
        </ul>

        
    </nav>
    <div class="dropDown">
        <ul class="drop-list">
            <a href="/index.html"><li class="listno ">Home</li></a>
            <li class="listno ">About</li>
            <li class="listno">Contact</li>
            <li><span class="download " id="download">Download</span></li></ul>
    </div>

    <!-- .................................................................... -->
    
    <div class="noteContainer">
    
    <!------------------------ paste code here   ---------------------------------- -->
    <div style="margin: 5px 0;">
        <p><strong>UNIT - 5</strong></p>
        <p><strong><u>&nbsp;</u></strong></p>
        <p><strong><u>DATA:</u></strong></p>
        <p>Data is the row material that can be processed for any computing machine.&nbsp;E.g.: Employee name, product name, Image, Mobile number, etc.</p>
        <p>&nbsp;</p>
        <p><strong><u>DIGITAL DATA DEFINITION</u></strong><strong>:</strong></p>
        <ul>
          <li>Digital data is data that shows other forms of data by using specific machine language systems that interprets by a variety of technologies.</li>
          <li>The binary system is the most fundamental of these systems.</li>
          <li>Which stores complex, audio, video and also text information in a series of binary characters, traditionally the 1&rsquo;s and 0&rsquo;s or the values &lsquo;ON&rsquo; and &lsquo;OFF&rsquo;.</li>
          <li>The greatest strength of digital data is that all very complex analog inputs can be represented with the binary system.</li>
        </ul>
        <p>In simple words,Digital data is defined as the data that is stored on digital format may be in the form of a picture, document or video etc.</p>
        <p>It is the data that is not physical but stored in digital form.</p>
        <p>&nbsp;</p>
        <p><strong><u>FEATURES OF DIGITAL DATA</u></strong><strong>:</strong></p>
        <ul>
          <li>From early primitive digital data design to new, highly sophisticated, massive binary data volumes, digital data seeks to capture essentials of the physical world.</li>
          <li>This is done in different ways, but with specific techniques to capture various real events and convert the into digital form.</li>
          <li>The new digital data is somewhat similar to the old data systems that convert a physical view or a scene into a chemical film.</li>
          <li>Digital data records visual information in a bitmap, which stores a particular color property for each bit on a precise.</li>
          <li>With the use of an essential data transfer system, a digital image was created. It uses similar techniques to record audio streams in digital form.</li>
          <li>Digit Data can be classified into three forms:</li>
          <li>Structured Data</li>
          <li>Semi-structured Data</li>
          <li>Structured Data</li>
        </ul>
        <p>&nbsp;</p>
        <p><strong><u>St</u></strong><strong><u>ructured Data</u></strong>:-</p>
        <ul>
          <li>Well formed</li>
          <li>Stored in tabular format</li>
          <li>It is clearly defined</li>
          <li>The rows and columns are related to each other.</li>
          <li>Structured data is stored in Relational Database(RDBMS).</li>
          <li>Data is stored in a per-definedData Model.(How data is connected to each other and how they are processed and stored inside the system. E.g.: Relational DM, E-R DM, Object-based DM, etc.)</li>
          <li>Example:- SQL Databases, Excel files (The spreadsheetin tabular format and very well organize&nbsp;or very well discipline)</li>
        </ul>
        <p>&nbsp;</p>
        <p><strong><u>Unstructured Data</u></strong><strong><u>:-</u></strong></p>
        <ul>
          <li>No per-defined</li>
          <li>No Data Model.</li>
          <li>Data is irregular and ambiguous. (Uncertain in nature means any data text, image, number, video, anything)</li>
          <li>Easiest to extract data.</li>
          <li>Hence 80 &ndash; 90% of data is unstructured.(Text,numbers, audio, video, images, messages, social media posts, etc)</li>
          <li>It is a complex task to analyze such data.</li>
          <li>So unstructured data is the most useful kind of data.</li>
          <li>It provides a lot of information.</li>
          <li>It stored in the data lake.</li>
          <li>Example:- Facebook, Instagram, YouTube, etc.</li>
        </ul>
        <p>&nbsp;</p>
        <p>&nbsp;</p>
        <p><strong><u>Semi &ndash; Structured Data</u></strong></p>
        <ul>
          <li>It falls between structured and unstructured data.</li>
          <li>It is a combination of both structured and unstructured data. Example:- Emails, XML, WWW</li>
        </ul>
        
        <p><strong><u>Data</u></strong></p>
        <p>Data is information that has been translated into a form that is efficient for movement or processing.</p>
        <p>Data is the raw material that can be processed for any computing machine.</p>
        <p>For example &minus; Employee name, Product name, Name of the student, Marks of the student, Mobile number, Image etc.</p>
        <p><strong>&nbsp;</strong></p>
        <p><strong>What is Small Data?</strong></p>
        <p>Small data&nbsp;is&nbsp;data that is 'small' enough for human comprehension.</p>
        <p>The term "big data" is about machines and "small data" is about people.</p>
        <p>Almost everything currently in progress and&nbsp;the data of which can be acquired in an Excel file.</p>
        <p>Data that is simple enough to be used for human understanding in such a volume and structure format&nbsp;that makes it accessible, concise, and workable is known as small data.</p>
        <p><strong>&nbsp;</strong></p>
        <p><strong>What is Big</strong><strong>&nbsp;D</strong><strong>ata?</strong></p>
        <p>a.In simple language, big data is a collection of data that is larger, more complex than traditional data, and yet growing exponentially with time.</p>
        <p>b.It is so huge that no traditional data management software or tool can manage, store, or can process it efficiently.</p>
        <ol>
          <li>The Big Data collection is done by using pipelines having queues like AWS Kinesis or Google Pub / Sub to balance high-speed data . Size of Data is more than Terabytes.</li>
          <li>Numerous variety of data set including tabular data, text, audio, images, video, logs, JSON etc.(Non Relational). Usually requires distributed storage systems on cloud or in external file systems.</li>
        </ol>
        <p>e.It is therefore important for analysts to thoroughly dig the whole thing into making it relevant and useful to make proper business decisions.</p>
        <ol>
          <li>Securing Big Data systems are much more complicated. Best security practices include data encryption, cluster network isolation, strong access control protocols etc.</li>
        </ol>
        <p>g.In short, datasets that are really huge and complex that conventional data processing techniques can not manage them are known as big data.</p>
        <p>&nbsp;</p>
        <p>In recent years, Big Data was defined by the &ldquo;5Vs&rdquo; but now generally defined by five characteristics: volume, velocity, variety, and veracity, value.</p>
        <ol>
          <li><strong><u> Volume: </u></strong></li>
        </ol>
        <p>a.The name &lsquo;Big Data&rsquo; itself is related to a size which is enormous.</p>
        <p>b.Volume is a huge amount of data.</p>
        <p>c.To determine the value of data, size of data plays a very crucial role. If the volume of data is very large then it is actually considered as a &lsquo;Big Data&rsquo;. This means whether a particular data can actually be considered as a Big Data or not, is dependent upon the volume of data.</p>
        <p>d.Hence while dealing with Big Data it is necessary to consider a characteristic &lsquo;Volume&rsquo;.</p>
        <p>Example: In the year 2016, the estimated global mobile traffic was 6.2 Exabytes(6.2 billion GB) per month. Also, by the year 2020 we will have almost 40000 Exabyte&nbsp;of data.</p>
        <p>&nbsp;</p>
        <ol start="2">
          <li><strong><u> Velocity:</u></strong></li>
        </ol>
        <p>a.Velocity refers to the high speed of accumulation of data.</p>
        <p>b.In Big Data velocity data flows in from sources like machines, networks, social media, mobile phones etc.</p>
        <p>c.There is a massive and continuous flow of data. This determines the potential of data that how fast the data is generated and processed to meet the demands.</p>
        <p>d.Sampling data can help in dealing with the issue like &lsquo;velocity&rsquo;.</p>
        <p>Example: There are more than 3.5 billion searches per day are made on Google. Also, FaceBook users are increasing by 22%(Approx.) year by year.</p>
        <p>&nbsp;</p>
        <ol start="3">
          <li><strong><u> Variety:</u></strong></li>
        </ol>
        <p>a.It refers to nature of data that is structured, semi-structured and unstructured data.</p>
        <p>b.It also refers to heterogeneous sources.</p>
        <p>c.Variety is basically the arrival of data from new sources that are both inside and outside of an enterprise. It can be structured, semi-structured and unstructured.</p>
        <p>&nbsp;</p>
        <ol start="4">
          <li><strong><u> Veracity:</u></strong></li>
        </ol>
        <p>a.It refers to inconsistencies and uncertainty in data, that is data which is available can sometimes get messy and quality and accuracy are difficult to control.</p>
        <p>b.Big Data is also variable because of the multitude of data dimensions resulting from multiple disparate data types and sources.</p>
        <p>c.Example: Data in bulk could create confusion whereas less amount of data could convey half or Incomplete Information.</p>
        <p>&nbsp;</p>
        <ol start="5">
          <li><strong><u> Value:</u></strong></li>
        </ol>
        <p>a.After having the 4 V&rsquo;s into account there comes one more V which stands for Value!. The bulk of Data having no Value is of no good to the company, unless you turn it into something useful.</p>
        <p>b.Data in itself is of no use or importance but it needs to be converted into something valuable to extract Information. Hence, you can state that Value! is the most important V of all the 5V&rsquo;s.</p>
        <p>Thus Big Data includes huge volume, high velocity, and extensible variety of data. The data in it will be of three types.</p>
        <p><u>1.Structured data&nbsp;</u>&minus; Relational data.</p>
        <p>This data is basically an organized data. It generally refers to data that has defined the length and format of data.</p>
        <p>&nbsp;</p>
        <p><u>&nbsp;</u></p>
        <p><u>2.Semi Structured data</u>&nbsp;&minus; XML data.</p>
        <p>This data is basically a semi-organized&nbsp;data. It is generally a form of data that do not conform to the formal structure of data. Log files are the examples of this type of data.</p>
        <p>&nbsp;</p>
        <p><u>3.Unstructured data&nbsp;</u>&minus; Word, PDF, Text, Media Logs.</p>
        <p>This data basically refers to unorganized data. It generally refers to data that doesn&rsquo;t fit neatly into the traditional row and column structure of the relational database. Texts, pictures, videos etc. are the examples of unstructured data which can&rsquo;t be stored in the form of rows and columns.</p>
        <p><strong><u>&nbsp;</u></strong></p>
        <p><strong><u>BIG DATA ANALYTIC :</u></strong></p>
        <p>The process of analysis of large volumes of diverse data sets, using advanced analytic techniques is referred to as Big Data Analytic.These diverse data sets include structured, semi-structured, and unstructured data, from different sources, and in different sizes from terabytes to petabytes. We also reckon them as big data.</p>
        <p>&nbsp;</p>
        <p>Big Data is a term that is used for data sets whose size or type is beyond the capturing, managing, and processing ability of traditional rotational databases. The database required to process big data should have low latency that traditional databases don&rsquo;t have.</p>
        <p>&nbsp;</p>
        <p>Big data has one or more characteristics among high volume, high velocity, and high variety.&nbsp;Big <a href="https://www.analyticssteps.com/blogs/what-data-analytics-and-its-types">data analytics </a>enables analysts, researchers, and business users to leverage big data, which was previously inaccessible and unusable, for faster and better decision- making.</p>
        <p><strong><u>Types of Big Data </u></strong><strong><u>Analytic</u></strong><strong><u>:</u></strong></p>
        <p>The different types of data require different approaches. This different approach of analytics gives rise to the four different types of Big data analytic.</p>
        <ol>
          <li>Descriptive Analytic</li>
          <li>Diagnostic Analytic</li>
          <li>Predictive Analytic</li>
          <li>Prescriptive Analytic</li>
        </ol>
        
        <p>&nbsp;</p>
        <p>&nbsp;</p>
        <p><em><u><b>Types of Big Data Analytic</b></u></em></p>
        <p>&nbsp;</p>
        <p>&nbsp;</p>
       
        <h1><u>Descriptive</u><u>&nbsp;</u><u>Analytic:</u></h1>
        <p>Descriptive Analytic is considered a useful technique for uncovering patterns within a certain segment of customers. It simplifies the data and summarizes past data into a readable form.<a href="https://www.analyticssteps.com/blogs/overview-descriptive-analysis">Descriptive analytics </a>provide insights into what has occurred in the past and with the trends to dig into for more detail. This helps in creating reports like a company&rsquo;s revenue, profits, sales, and so on.</p>
        <p>&nbsp;</p>
        <h1><u>Diagnostic Analytic:</u></h1>
        <p>Diagnostic Analytic, as the name suggests, gives a diagnosis to a problem. It gives a detailed and in-depth insight into the root cause of a problem.Data scientists turn to this analytic&nbsp;craving for the reason behind a particular happening. Techniques like drill-down, data mining, and data recovery, churn reason analysis, and customer health score analysis are all examples of diagnostic analytic.</p>
        <p>&nbsp;</p>
        <p>In business terms, diagnostic analytic is useful when you are researching the reasons leading churn indicators and usage trends among your most loyal customers.A use case for diagnostic analytic can be an <a href="https://www.analyticssteps.com/blogs/rise-e-commerce-amid-lockdown">e-commerce </a>company. Given the situation that the sales of the company have gone down even though customers are adding products to their carts.The possible reasons behind this problem can be: the form didn't load correctly, the shipping charges are high, and not enough payment methods are available.Taking the help of diagnostic analytic, the company comes out with a specific reason and then works on that to resolve the issue.</p>
        <p>&nbsp;</p>
        <h1><u>Predictive Analytic:</u></h1>
        <p>Predictive Analytic, as can be discerned from the name itself, is concerned with predicting future incidents. These future incidents can be market trends, consumer trends, and many such market-related events.&nbsp;This type of analytic makes use of historical and present data to predict future events. This is the most commonly used form of analytic among businesses.</p>
        <p>&nbsp;</p>
        <p>Predictive analytic&nbsp;doesn&rsquo;t only work for the service providers but also for the consumers. It keeps track of our past activities and based on them, predicts what we may do next.Predictive analytic uses models like data mining, AI, and machine learning to analyze current data and forecast what might happen in specific scenarios.&nbsp;Examples of Predictive analytic include next best offers, churn risk, and renewal risk analysis.We can take the example of PayPal (<a href="https://www.analyticssteps.com/blogs/stripe-paypal-right-payment-platform-online-business">Stripe vs PayPal</a>) to understand how businesses use predictive analytic.&nbsp;The company determines the steps they need to take the steps to protect their&nbsp;client&rsquo;s fraudulent transactions. It uses all past payment data and user behavior data to predict fraudulent activities.</p>
        <p>&nbsp;</p>
        <h1><u>Prescriptive Analytic:</u></h1>
        <p>Prescriptive analytic is the most valuable yet underused form of analytic. It is the next step in predictive analytic. The prescriptive analysis explores several possible actions and suggests actions depending on the results of descriptive and predictive analytic of a given data&nbsp;set.</p>
        <br />
        <p>Prescriptive analytic is a combination of data and various business rules. The data of prescriptive analytic can be both internal (organizational inputs) and external (social media insights).Prescriptive analytic allows businesses to determine the best possible solution to a problem. When combined with predictive analytic, it adds the benefit of manipulating a future occurrence like mitigate future risk.Examples of prescriptive analytic for customer retention is the next best action and next best offer analysis.A use case of prescriptive analytic can be the Aurora Health Care system. It saved $6 million by reducing the readmission rates by 10%.Prescriptive analytic has good use in the healthcare industry. It can be used to enhance the process of drug development, finding the right patients for clinical trials, etc.</p>
        <p>&nbsp;</p>
        <p><strong>Hadoop</strong></p>
        <p>When internet was introduced, it took the world by storm by giving tons of data generated in various forms. Semi structured and structured data was available in the form of E-mail, audio and video. All this data became collectively known as &ldquo;Big Data&rdquo;. It became nearly impossible to handle this big data and storage unit and processor combination was not enough. Solution to this problem was- HADOOP.</p>
        <p>Hadoop is an open source framework. It is provided by Apache to process and analyze very huge volume of data. It is written in Java and currently used by Google, Facebook, Linked In, Yahoo, Twitter etc.Hadoop is a collection of open source framework that is used to efficiently store and process large data sets ranging in size from gigabytes to petabytes of data.&nbsp;Hadoop allows clustering multiple computers to analyze massive data sets in parallel more quickly.</p>
        <p>&nbsp;</p>
        <p><strong><u>Modules of Hadoop</u></strong><strong><u>/ Analyzing data with Hadoop: </u></strong></p>
        <p>Hadoop consists of four modules:</p>
        <p><u>Hadoop Distributed File System or HDFS</u>:&nbsp;</p>
        <p>HDFS is a distributed file system designed to run on low-cost hardware. HDFS outperforms conventional file systems in terms of data throughput. It&rsquo;s a Java-based distributed file system that lets you store large amounts of data across multiple nodes (machines).</p>
        <p>HDFS stands for Hadoop Distributed File System. Storing massive data on one computer is feasible hence data is distributed among many computers and stored in blocks. Eg- If you have 600 megabytes of data the HDFS splits data into multiple blocks of data that are then stored on several data nodes in cluster. HDFS makes copy of data and stores it across multiple systems. Hence it is fault tolerant.</p>
        <p>&nbsp;</p>
        <p><u>Map Reduce</u><u>:</u>&nbsp;</p>
        <p>It is a framework that aids Java programs in parallel data computation. It consists of Map and Reduce tasks. The map task transforms input data into a data&nbsp;set that can be computed using key-value pairs. The output of the Map task is consumed by the Reduce task, which then produces the final result.</p>
        <p>After storing the data it needs to be processed so the second component map reduce comes in. Entire data would be processed on a single machine having a single processor, this consumed time and was inefficient. To overcome this map reduce separated data into parts and processed each of them separately on different data nodes. All this is done by writing a simple program. It improves load balancing and saves time.</p>
        <p>&nbsp;</p>
        <p><u>YARN:&nbsp;</u></p>
        <p>An Abbreviation of Yet Another Resource Negotiator is used for scheduling the jobs and managing the Hadoop clusters.&nbsp;As the map reduce job ready we will run it on hadoop cluster. These are done with the help of set of resources such as ram, network, bandwidth and CPU. Multiple jobs are run on hadoop simultaneously. So, we require the resources to complete the task. In order to manage these resources we use Yarn the third component. Yarn processes job request and manages cluster resources.</p>
        <p>&nbsp;</p>
        <p><u>Hadoop Common:&nbsp;</u></p>
        <p>Provides a collection of shared Java libraries that can be used for all Hadoop modules.&nbsp;Hadoop common or Common utilities are nothing but our java library and java files or we can say the java scripts that we need for all the other components present in a Hadoop cluster. these utilities are used by HDFS, YARN, and MapReduce for running the cluster. Hadoop Common verify that Hardware failure in a Hadoop cluster is common so it needs to be solved automatically in software by Hadoop Framework.</p>
        <p>&nbsp;</p>
        <p><strong><u>Hadoop Architecture</u></strong></p>
        <p>The Hadoop architecture is a package of the file system, MapReduce engine and the HDFS (Hadoop Distributed File System). The MapReduce engine can be MapReduce/MR1 or YARN/MR2.</p>
        <p>A Hadoop cluster consists of a single master and multiple slave nodes. The master node includes Job Tracker, Task Tracker, NameNode, and DataNode whereas the slave node includes DataNode and TaskTracker.</p>
        <p>&nbsp;</p>
        <p><strong><u>Hadoop Distributed File System</u></strong></p>
        <p>The Hadoop Distributed File System (HDFS) is a distributed file system for Hadoop. It contains a master/slave architecture. This architecture consist of a single Name&nbsp;Node performs the role of master, and multiple Data&nbsp; Nodes performs the role of a slave.&nbsp;Both Name&nbsp;Node and Data&nbsp;Node are capable enough to run on commodity machines. The Java language is used to develop HDFS. So any machine that supports Java language can easily run the Name&nbsp;Node and Data&nbsp;Node software.</p>
        <p><u>Name</u><u>&nbsp;</u><u>Node</u></p>
        <p>It is a single master server exist in the HDFS cluster.&nbsp;As it is a single node, it may become the reason of single point failure.&nbsp;It manages the file system name&nbsp;space by executing an operation like the opening, renaming and closing the files.It simplifies the architecture of the system.</p>
        <p><u>Data</u><u>&nbsp;</u><u>Node</u></p>
        <p>The HDFS cluster contains multiple Data&nbsp;Nodes.&nbsp;Each Data&nbsp;Node contains multiple data blocks.</p>
        <p>These data blocks are used to store data.&nbsp;It is the responsibility of Data&nbsp;Node to read and write requests from the file system's clients.&nbsp;It performs block creation, deletion, and replication upon instruction from the Name&nbsp; Node.</p>
        <p><u>Job Tracker</u></p>
        <p>The role of Job Tracker is to accept the Map&nbsp;Reduce jobs from client and process the data by using Name&nbsp;Node.&nbsp;In response, Name&nbsp;Node provides metadata to Job Tracker.</p>
        <p><u>Task Tracker</u></p>
        <p>It works as a slave node for Job Tracker.&nbsp;It receives task and code from Job Tracker and applies that code on the file. This process can also be called as a Mapper.</p>
        <p><u>Map</u><u>&nbsp;</u><u>Reduce Layer</u></p>
        <p>The Map&nbsp;Reduce comes into existence when the client application submits the Map&nbsp;Reduce job to Job Tracker. In response, the Job Tracker sends the request to the appropriate Task Trackers. Sometimes, the Task&nbsp;Tracker fails or time out. In such a case, that part of the job is rescheduled.</p>
        <p><u>&nbsp;</u></p>
        <p><strong><u>Advantages of Hadoop:</u></strong></p>
        <ol>
          <li>Varied Data Sources</li>
        </ol>
        <p>Hadoop accepts a variety of data. Data can come from a range of sources like email conversation, social media etc. and can be of structured or unstructured form.&nbsp;Hadoop can derive value from diverse data. Hadoop can accept data in a text file, XML file, images, CSV files etc.</p>
        <ol start="2">
          <li>Cost-effective</li>
        </ol>
        <p>Hadoop is an economical solution as it uses a cluster of commodity hardware to store data.</p>
        <p>&nbsp;Commodity hardware is cheap machines hence the cost of adding nodes to the framework is not much high.</p>
        <p>&nbsp;This requires less machine to store data as the redundant data decreased significantly.</p>
        <ol start="3">
          <li>Performance</li>
        </ol>
        <p>Hadoop with its distributed processing and distributed storage architecture processes huge amounts of data with high speed.Hadoop even defeated supercomputer the fastest machine in 2008. It divides the input data file into a number of blocks and stores data in these blocks over several nodes. It also divides the task that user submits into various sub-tasks which assign to these worker nodes containing required data and these sub-task run in parallel thereby improving the performance.</p>
        <p>&nbsp;</p>
        <p>4.Open Source</p>
        <p>Hadoop is an open source technology i.e. its source code is freely available. We can modify the source code to suit a specific requirement.</p>
        <p>&nbsp;</p>
        <p><strong><u>Disadvantages of Hadoop:</u></strong></p>
        <p>Issue With Small Files</p>
        <p>Hadoop is suitable for a small number of large files but when it comes to the application which deals with a large number of small files, Hadoop fails here. A small file is nothing but a file which is significantly smaller than Hadoop&rsquo;s block size which can be either 128MB or 256MB by default. These large number of small files overload the Name&nbsp;node as it stores name&nbsp;space for the system and makes it difficult for Hadoop to function.</p>
        <p>&nbsp;Vulnerable By Nature</p>
        <p>Hadoop is written in<a href="https://data-flair.training/blogs/java-tutorial/">&nbsp;Java which is a widely used programming language</a>&nbsp;hence it is easily exploited by cyber&nbsp;criminals which makes Hadoop vulnerable to security breaches.</p>
        <p>&nbsp;</p>
        <p><strong><u>History of Hadoop</u></strong></p>
        <p>The Hadoop was started by Doug Cutting and Mike Cafarella in 2002. Its origin was the Google File System paper, published by Google.</p>
        <p>&nbsp;</p>
        <p>&nbsp;</p>
        <p>&nbsp;</p>
        <ul>
          <li>In 2002, Doug Cutting and Mike Cafarella started to work on a project,&nbsp;Apache Natch.&nbsp;It is an open source web crawler software project.</li>
          <li>While working on Apache Natch, they were dealing with big data. To store that data they have to spend a lot of costs which becomes the consequence of that project. This problem becomes one of the important reason for the emergence of Hadoop.</li>
          <li>In 2003, Google introduced a file system known as GFS (Google file system). It is a proprietary distributed file system developed to provide efficient access to data.</li>
          <li>In 2004, Google released a white paper on Map Reduce. This technique simplifies the data processing on large clusters.</li>
          <li>In 2005, Doug Cutting and Mike Cafarella introduced a new file system known as NDFS (Nutch Distributed File System). This file system also includes Map reduce.</li>
          <li>In 2006, Doug Cutting quit Google and joined Yahoo. On the basis of the Nutch project, Dough Cutting introduces a new project Hadoop with a file system known as HDFS (Hadoop Distributed File System). Hadoop first version 0.1.0 released in this year.</li>
          <li>Doug Cutting gave named his project Hadoop after his son's toy elephant.</li>
          <li>In 2007, Yahoo runs two clusters of 1000 machines.</li>
          <li>In 2008, Hadoop became the fastest system to sort 1 terabyte of data on a 900 node cluster within 209 seconds.</li>
        </ul>
        <p>&nbsp;</p>
      </div>

    </div>
    <footer class="footer">
        <div class="container">
            <div class="row">
                <div class="footer-col">
                    <div class="webLogo">
                        <h2 class="logo">MCA_<span class="notes_text"> Notes</span></h2>
                    </div>
                </div>
                <div class="footer-col">
                    <h4>get help</h4>
                    <ul>
                        <li><a href="#">About US</a></li>
                        <li><a href="#">FAQ</a></li>
                        <li><a href="#">Privacy Policy</a></li>
                        <li><a href="#">Terms & Condition</a></li>

                    </ul>
                </div>
                <div class="footer-col">
                    <h4>All Link</h4>
                    <ul>
                        <li><a href="#">Home</a></li>
                        <li><a href="#">Contact US</a></li>
                        <li><a href="#">About Us</a></li>
                        <li><a href="#">Syllabus</a></li>
                        <li><a href="#">Quetion Paper</a></li>
                    </ul>
                </div>
                <div class="footer-col">
                    <h4>follow us</h4>
                    <div class="social-links">
                        <a href="#"><i class="fab fa-facebook-f"></i></a>
                        <a href="#"><i class="fab fa-twitter"></i></a>
                        <a href="#"><i class="fab fa-instagram"></i></a>
                        <a href="#"><i class="fab fa-linkedin-in"></i></a>
                    </div>
                </div>
                
            </div>
        </div>
        
    </footer>
    <script src="/gSap.js"></script>
    <script src="/script.js"></script>
</body>

</html>